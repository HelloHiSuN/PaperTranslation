Web内容提取-对过去和关于未来的思考的元分析

在这篇论文中，我们呈现了对几种网络内容提取算法的元分析，并且对未来网络内容提取的未来做一些建议。
首先，我们发现近乎所有的网络内容提取器并没有考虑现代网页中非常大的、不断增长的部分。
其次，很好理解的是，包装诱导提取器在网页变化的时候倾向于停止；启发式/特征工程提取器被认为是对网页演变免疫的。但是我们发现情况并非如此：由于网站形式和实践的演变，启发式内容提取器性能也趋向于随着时间而降级。
我们总结了对未来工作中处理这些问题和其他发现的建议。

I.介绍
在数据挖掘和信息检索的更大范围内，内容提取的领域主要涉及对诸如网页或网站这类文档的主要文本的识别。
这主要是因为诸如搜索引擎、移动设备和各种分析工具这些利用网页数据的工具在与主要内容无关的文本引入噪声时会表露出较差的性能[11,23]。

作为响应，内容提取领域已经开发出了一些从一个给定的网页或一些网页集合(即网站)中提取主要内容的方法[20,32]。
通常情况下，这些内容提取方法是基于模式挖掘和精心制作的规则。
在其他情况下，内容提取器通过检查网站中的多个网页来学习网页的一般架构[1,6,7,18]。
这两类内容提取器被分别称为启发式提取和包装诱导提取，每一类的算法都有它自己的价值和缺点。
一般来说，包装诱导方法比启发式方法更准确，但是需要一些数量的训练数据来初始地诱导一个适当的包装器。
相反地，启发式提取方法能够在没有诱导步骤的情况下运行，但是通常准确性较低。

对于包装诱导的内容提取方式的主要的批评是它学习到的规则通常是很脆弱的，它不能处理即使是很小的网页模板改动的情况[12]。
当一个网站像他们经常做的那样更新它的模板时，已经学习了规则的包装器需要重新执行代价昂贵的诱导步骤来进行刷新。
一些对包装诱导方法的改进尝试将诱导提取规则对模板发生较小变化时变得更健壮[8,9,28]，但是对使规则更鲁棒的改进将不可避免的延迟[5]。

启发性方法经常因为缺乏一般性而受到批评。
也就是说，启发式方法可以在某种类型的网站(例如通讯社)上工作，但是在商业网站或留言板上不适用。
大多数方法还忽略了在渲染过程中由于外部引用调用产生动态下载或合并的内容(例如CSS,JavaScript,图像)的大部分网页。

本篇论文的目的不是调查整个的内容提取领域，所以我们抵制详细比较和对比众多已经发表的方法。
相反，在这篇论文中我们对这个领域的状态进行坦率的评估，提供对内容提取的有效性随时间变化的分析，并且对内容提取的未来提出建议。

在这篇论文中，我们做出了三点主要贡献：
1.我们定义Web上的内容的功能和呈现的变化矢量。
2.我们审查关于不断变化的Web的内容提取的状态。
3.我们对各种内容提取器进行时间的评估。

最后，我们呼吁改变内容提取的研究和发展方向。

Web实践的演变是这篇论文的核心主题。
一个科学学科应该努力使它的研究成果在一定时间内具有一些不变性。
当然，随着技术的改变，我们对它的研究也必须改变。
考虑到这一点，判断一个模型是否成功的一个方法是衡量它对于随时间变化的输入的稳定性或持久性。

为此，我们呈现一个案例研究的结果，它比较了包括新的和旧的内容提取算法在一个不断发展的数据集上的情况。
目的是鉴定哪些方法(如果有的话),是对Web实践的演变具有一定不变性的。

[表I 占位]
表I: 使用在这项研究的数据集。历经20年，来自10个网站，每个网站每5年爬取25个网页，总计1000个网页。

为此，我们从表I中列出的10个不同域名中收集了1000个网页的数据集，其中每个域名有2000年，2005年，2010年和2015年的一组页面。
每个网站每五年有25个HTML文档，一共100个文档。
这些文档是通过手动的和自动的方式从两种数据源收集而成：历史档案[24]和2015年这五年时期的网站本身。

我们检查了Web内容的传送和提取的演变，明确地指出最近的改变对已经存在的内容提取器的有效性的破坏。
为了明确的显示这一点，我们做了一项大案例研究，在其中我们比较了几个内容提取算法随时间变化的性情情况。
基于我们的发现，我们呼吁改变对内容提取进行的研究，并为未来的工作提出建议。

II.不断发展的Web实践
我们从对网络上传播的内容自从第一次构想以来发生的巨大的变化的观察开始。
内容提取的案例是围绕着这样的原理：HTML是一种标记语言，它描述网页看起来如何而不是网页的内容。
在这里，经典的形态与功能的争辩是显而易见的。
然而，近年来随着大量类似JavaScript的脚本语言的使用和HTML5的最终定稿，Web已经可以看见同时存在的形态与功能的结合和分离。
在这一节，我们论证因为Web技术已经改变，我们实施和评估内容提取的方式也必须改变。

A.形态与功能的演变
JavaScript. 
几乎所有的内容提取算法的实施是通过下载目标网页中的HTML，并且只有HTML。
在很多情况下，网页直接或间接的引用可以在加载过程中执行的数十个客户端脚本，即JavaScript文件。
大多数时候，内容提取器深知不会去下载所引用的脚本，即使JavaSctipt函数可以(并且经常这么做)完全的修改DOM和下载下来的HTML的内容。
事实上，大部分被内容提取技术明确声称获取的垃圾邮件和广告是通过JavaScript加载的，因此它们不应该是内容提取试验台的一部分。

CSS.
样式表提出了一个和JavaScript性质相似的问题，一个网站的显示内容的结构性的改变常是由内嵌在级联样式表中的指令来执行。
虽然CSS指令不像JavaScript函数那样具有表达性--他们是为了不同的目的构建的--样式表的缺省经常严重影响网页的渲染。
不幸的是，CSS使用的普及移除了提取器依赖的许多HTML提示。
使用了CSS，一个复杂的网站完全有可能是全部由div标签构成。

HTML5.
由HTML5引入的新的标记标准中包括了许多新的标签，例如main,article,header等，意在指定内容的语义。
HTML5的广泛采用正在进行中，因此目前还不清楚新的标记语言是否会或者如何被使用，以及会带来怎样的负面影响(如果有的话)。

[FIG.1 占位]
FIG.1: 网页http://www.kdd.org/kdd2015/在现代浏览器中被完全渲染(左)。禁用JavaScript的网页(中)。下载下来的不包含任何外部内容的静态渲染的网页(右)。
大部分提取器在右图上的网页执行。
[表II 占位]
表II: 一些HTML标签和属性的平均出现次数代表了我们的1000个新闻网页组成的数据集中在4个相同的5年期里的辅助源文件。
外部内容和客户端脚本的使用已经在快速稳定的增长。

HTML5中的语义标签实际上和HTML中的原始意图严重分离。
也就是说，HTML4原本是为了作为网页结构的标记而不是一个描述型语言。
事实上，普遍缺少语义的标签是内容提取算法起初被创建的一个主要原因。

Schema.org项目对HTML标记提供更进一步的语义补充。
Schema.org是主要Web搜索提供者的一项合作，以提供能够被嵌入到HTML4/5标签属性中的统一描述语言。
网站开发者们可以使用这些标签来对HTML数据表示的内容进行编码，例如，一个有name-itemprop属性的Person-itemtype能够被搜索引擎和其他Web服务来构建智能分析工具。
其他对HTML语言编码的努力可以在Microformats.org项目(HTML5属性的资源描述框架扩展)等其他一些地方发现。

[表III 占位]
表III: 来自Schema.org的itemscope,itemtype和itemprop标签与来自数据集中2015年子集的HTML5的ariticle和section的语义标签出现次数的平均值和中位数。
语义标签只能够在2015年的数据集中找到。

表III展现了我们2015年数据集中Schema.org和HTML5的语义标签的中位数和平均值。
我们发现我们爬取的9/10的网站已经采用了Schema.org的标签系统，9/10的网站已经采用HTML5的section和article标签(8/10的网站两者都采用)。

HTML5和Schema.org的出现和广泛采用减少了对很多提取工具的需求，因为HTML中的内容或数据已经被明确的标记和描述了。

AJAX.
传送给客户端的现代网页经常完全没有任何内容，内容通过AJAX在单独的JSON或XML消息中传递。
这些并不是罕见的情况，截至2015年4月，Web技术研究发现在所有网站中有67%在使用AJAX[25]。
因此，很容易想到绝大多数内容提取器在67%的情况下高估了他们的有效性，因为实际上最终的网页的可见的渲染大部分并不存在于HTML文件中。

事实上，在我们的实验中，我们发现许多内容提取器在NY Times文章中找到的最后一个词中出现最频繁的是"loading..."。

表II显示了一些HTML标签和属性的平均出现次数代表了我们的1000个新闻网页组成的数据集中的辅助源文件。












