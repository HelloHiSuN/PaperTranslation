Web内容提取-对过去和关于未来的思考的元分析

在这篇论文中，我们呈现了对几种网络内容提取算法的元分析，并且对未来网络内容提取的未来做一些建议。
首先，我们发现近乎所有的网络内容提取器并没有考虑现代网页中非常大的、不断增长的部分。
其次，很好理解的是，包装诱导提取器在网页变化的时候倾向于停止；启发式/特征工程提取器被认为是对网页演变免疫的。但是我们发现情况并非如此：由于网站形式和实践的演变，启发式内容提取器性能也趋向于随着时间而降级。
我们总结了对未来工作中处理这些问题和其他发现的建议。

I.介绍
在数据挖掘和信息检索的更大范围内，内容提取的领域主要涉及对诸如网页或网站这类文档的主要文本的识别。
这主要是因为诸如搜索引擎、移动设备和各种分析工具这些利用网页数据的工具在与主要内容无关的文本引入噪声时会表露出较差的性能[11,23]。

作为响应，内容提取领域已经开发出了一些从一个给定的网页或一些网页集合(即网站)中提取主要内容的方法[20,32]。
通常情况下，这些内容提取方法是基于模式挖掘和精心制作的规则。
在其他情况下，内容提取器通过检查网站中的多个网页来学习网页的一般架构[1,6,7,18]。
这两类内容提取器被分别称为启发式提取和包装诱导提取，每一类的算法都有它自己的价值和缺点。
一般来说，包装诱导方法比启发式方法更准确，但是需要一些数量的训练数据来初始地诱导一个适当的包装器。
相反地，启发式提取方法能够在没有诱导步骤的情况下运行，但是通常准确性较低。

对于包装诱导的内容提取方式的主要的批评是它学习到的规则通常是很脆弱的，它不能处理即使是很小的网页模板改动的情况[12]。
当一个网站像他们经常做的那样更新它的模板时，已经学习了规则的包装器需要重新执行代价昂贵的诱导步骤来进行刷新。
一些对包装诱导方法的改进尝试将诱导提取规则对模板发生较小变化时变得更健壮[8,9,28]，但是对使规则更鲁棒的改进将不可避免的延迟[5]。

启发性方法经常因为缺乏一般性而受到批评。
也就是说，启发式方法可以在某种类型的网站(例如通讯社)上工作，但是在商业网站或留言板上不适用。
大多数方法还忽略了在渲染过程中由于外部引用调用产生动态下载或合并的内容(例如CSS,JavaScript,图像)的大部分网页。

本篇论文的目的不是调查整个的内容提取领域，所以我们抵制详细比较和对比众多已经发表的方法。
相反，在这篇论文中我们对这个领域的状态进行坦率的评估，提供对内容提取的有效性随时间变化的分析，并且对内容提取的未来提出建议。

在这篇论文中，我们做出了三点主要贡献：
1.我们定义Web上的内容的功能和呈现的变化矢量。
2.我们审查关于不断变化的Web的内容提取的状态。
3.我们对各种内容提取器进行时间的评估。

最后，我们呼吁改变内容提取的研究和发展方向。

Web实践的演变是这篇论文的核心主题。
一个科学学科应该努力使它的研究成果在一定时间内具有一些不变性。
当然，随着技术的改变，我们对它的研究也必须改变。
考虑到这一点，判断一个模型是否成功的一个方法是衡量它对于随时间变化的输入的稳定性或持久性。

为此，我们呈现一个案例研究的结果，它比较了包括新的和旧的内容提取算法在一个不断发展的数据集上的情况。
目的是鉴定哪些方法(如果有的话),是对Web实践的演变具有一定不变性的。

[表I 占位]
表I: 使用在这项研究的数据集。历经20年，来自10个网站，每个网站每5年爬取25个网页，总计1000个网页。

为此，我们从表I中列出的10个不同域名中收集了1000个网页的数据集，其中每个域名有2000年，2005年，2010年和2015年的一组页面。
每个网站每五年有25个HTML文档，一共100个文档。
这些文档是通过手动的和自动的方式从两种数据源收集而成：历史档案[24]和2015年这五年时期的网站本身。

我们检查了Web内容的传送和提取的演变，明确地指出最近的改变对已经存在的内容提取器的有效性的破坏。
为了明确的显示这一点，我们做了一项大案例研究，在其中我们比较了几个内容提取算法随时间变化的性情情况。
基于我们的发现，我们呼吁改变对内容提取进行的研究，并为未来的工作提出建议。

II.不断发展的Web实践
我们从对网络上传播的内容自从第一次构想以来发生的巨大的变化的观察开始。
内容提取的案例是围绕着这样的原理：HTML是一种标记语言，它描述网页看起来如何而不是网页的内容。
在这里，经典的形态与功能的争辩是显而易见的。
然而，近年来随着大量类似JavaScript的脚本语言的使用和HTML5的最终定稿，Web已经可以看见同时存在的形态与功能的结合和分离。
在这一节，我们论证因为Web技术已经改变，我们实施和评估内容提取的方式也必须改变。

A.形态与功能的演变
JavaScript. 
几乎所有的内容提取算法的实施是通过下载目标网页中的HTML，并且只有HTML。
在很多情况下，网页直接或间接的引用可以在加载过程中执行的数十个客户端脚本，即JavaScript文件。
大多数时候，内容提取器深知不会去下载所引用的脚本，即使JavaSctipt函数可以(并且经常这么做)完全的修改DOM和下载下来的HTML的内容。
事实上，大部分被内容提取技术明确声称获取的垃圾邮件和广告是通过JavaScript加载的，因此它们不应该是内容提取试验台的一部分。

CSS.
样式表提出了一个和JavaScript性质相似的问题，一个网站的显示内容的结构性的改变常是由内嵌在级联样式表中的指令来执行。
虽然CSS指令不像JavaScript函数那样具有表达性--他们是为了不同的目的构建的--样式表的缺省经常严重影响网页的渲染。
不幸的是，CSS使用的普及移除了提取器依赖的许多HTML提示。
使用了CSS，一个复杂的网站完全有可能是全部由div标签构成。

HTML5.
由HTML5引入的新的标记标准中包括了许多新的标签，例如main,article,header等，意在指定内容的语义。
HTML5的广泛采用正在进行中，因此目前还不清楚新的标记语言是否会或者如何被使用，以及会带来怎样的负面影响(如果有的话)。

[FIG.1 占位]
FIG.1: 网页http://www.kdd.org/kdd2015/在现代浏览器中被完全渲染(左)。禁用JavaScript的网页(中)。下载下来的不包含任何外部内容的静态渲染的网页(右)。
大部分提取器在右图上的网页执行。
[表II 占位]
表II: 一些HTML标签和属性的平均出现次数代表了我们的1000个新闻网页组成的数据集中在4个相同的5年期里的辅助源文件。
外部内容和客户端脚本的使用已经在快速稳定的增长。

HTML5中的语义标签实际上和HTML中的原始意图严重分离。
也就是说，HTML4原本是为了作为网页结构的标记而不是一个描述型语言。
事实上，普遍缺少语义的标签是内容提取算法起初被创建的一个主要原因。

Schema.org项目对HTML标记提供更进一步的语义补充。
Schema.org是主要Web搜索提供者的一项合作，以提供能够被嵌入到HTML4/5标签属性中的统一描述语言。
网站开发者们可以使用这些标签来对HTML数据表示的内容进行编码，例如，一个有name-itemprop属性的Person-itemtype能够被搜索引擎和其他Web服务来构建智能分析工具。
其他对HTML语言编码的努力可以在Microformats.org项目(HTML5属性的资源描述框架扩展)等其他一些地方发现。

[表III 占位]
表III: 来自Schema.org的itemscope,itemtype和itemprop标签与来自数据集中2015年子集的HTML5的ariticle和section的语义标签出现次数的平均值和中位数。
语义标签只能够在2015年的数据集中找到。

表III展现了我们2015年数据集中Schema.org和HTML5的语义标签的中位数和平均值。
我们发现我们爬取的9/10的网站已经采用了Schema.org的标签系统，9/10的网站已经采用HTML5的section和article标签(8/10的网站两者都采用)。

HTML5和Schema.org的出现和广泛采用减少了对很多提取工具的需求，因为HTML中的内容或数据已经被明确的标记和描述了。

AJAX.
传送给客户端的现代网页经常完全没有任何内容，内容通过AJAX在单独的JSON或XML消息中传递。
这些并不是罕见的情况，截至2015年4月，Web技术研究发现在所有网站中有67%在使用AJAX[25]。
因此，很容易想到绝大多数内容提取器在67%的情况下高估了他们的有效性，因为实际上最终的网页的可见的渲染大部分并不存在于HTML文件中。

事实上，在我们的实验中，我们发现许多内容提取器在NY Times文章中找到的最后一个词中出现最频繁的是"loading..."。

表II显示了一些HTML标签和属性的平均出现次数代表了我们的1000个新闻网页组成的数据集中的辅助源文件。
在该表中，src指可以引用多种文件类型的公共标签属性的出现次数。
link指的是常用来(尽管不是很必要)引用外部CSS文件的HTML的<link>标签的出现次数。
iframe指的是将其他HTML文档嵌入到当前HTML文档的HTML标签出现的次数。
script指的是常用来指出客户端脚本例如(但不是必须的)JavaScript的HTML标签出现的次数。
js指的是引用外部JavaScript文件出现的次数；同样的，css指的是引用外部CSS文件出现的次数。
jquery列展示了网页中通过jQuery库使用AJAX所占的百分比；可替代的AJAX库虽然有发现但是他们的出现比例特别小。

上述观察表明，在许多方面，Web正在趋向于进一步的形式和内容的解耦：
JavaScript将渲染DOM从下载的HTML中解耦，
CSS类似地将最终的页面显示与下载的HTML分离，
并且AJAX可以让HTML和可提取的内容完全分离成不同的文件。
然而，尽管有这些趋势，大多数内容提取方法依赖于静态下载的HTML文件。

图1突出显示了为什么这样被认为是一个坏的实践，图1是网页http://kdd.org/kdd2015分别在浏览器下(左)、去除JavaScript情况下(中)和仅有静态HTML文档(右)情况下的渲染情况。
传递给终端用户的信息以渲染版本的完整形式呈现；因此，内容提取器应该努力在完全渲染的文档(左)中操作，而不是像现在这样仅提取HTML(右)。

B.跟上Web的变化
网页展示在很短的时间内发生显著的变化。
内容提取算法试图跟上演变的网页，但是许多内容提取算法很快被淘汰。

违反直觉的是，尽管网站数量增长，它的展现样式看起来的确在减少。
由于各种原因，同一个网站的大多数网页看起来非常相似。
市场营销和品牌管理通常决定一个网站的风格与竞争对手不同，但是与同一网站中的其他页面相似。

包装感应。
Web站点中页面的自相似性源于绝大多数网站使用脚本来生成从后端数据库检索的网页内容。
由于网页在同一个网站中的结构相似性，可以对页面生成过程进行逆向工程，以删除网站的结构，只留剩余的内容[1,6,7,8]。

一次在一个网站上诱发包装器，通常只需要一些标签的例子。
一旦经过训练，包装器可以以近乎完美的准确度提取信息。
不幸的是，包装诱导技术假设网站模板不会改变。
即使对网站模板或数据库模式进行微小的调整也会破坏诱发的包装器，并且需要重新进行训练。
尝试学习更鲁棒的规则的，对一些网页模板微小改变的免疫的包装器已经有所成功，但是即使是最强大的包装器规则最终也会被破坏[8,12]。

启发式和特征工程。
其他工作集中精力于将某些启发式逻辑标识为内容提取的信号而不是去学习固定规则来进行内容提取。
各种不同的启发式方法令人印象深刻，通过各种特征的组合进行学习的统计模型在很多情况下可以和基于包装感应的提取器相媲美。

每一个方法和算法都是在Web演变的不同时期发明的，并且关注于Web内容的不同方面。
从各种方法中我们选择了来自不同时期的11个算法列于表IV。

[表IV 占位]
表IV：内容提取算法，以及它们的引用和发布时间。*RoadRunner是包装感应算法；其它都是启发式方法。

每一个算法，启发式逻辑，模型和方法论都是基于Web在发展过程中的形式和功能。
每一个都在当时的Web状态下进行了评估，想必是在发布之前。
此外，每一个算法都不考虑JavaScript，CSS或者AJAX对网页的改变。因此，如图一所示，大部分网页也许并没有被提取。

III.案例学习
我们展现了一个学习案例，是关于对比内容提取算法(不论是新的还是旧的)在一个不断变化的数据集中的表现。
目的是测试内容提取器在随着网站演变的可变性表现。
所以，对于每一个网站的每一个五年期中的每一个网页来说，黄金数据集是由第二作者手工创建的。
每一个Web内容提取器企图提取网页的主要内容。

表IV的前七个内容提取器，我们是使用的CombineE System的实现[13]。
Eatiht、BoilerPipe和CETR的实现在网上都是可用的。
BoilerPipe提供了一个标准的实现，以及一个文章提取器(AE),句子提取器(Sen),一个由KrdWrd-Canola语料库[26]上的数据训练的提取器和两个"单词数量"提取器：一个决策树诱导提取器(W)和一个手工调整到每个内容区域至少15个词的决策树诱导提取器(15W)。
CETR有一个默认算法以及基于标签比的标准偏差阈值选项(Th)和一维聚集选项(1D)。
有关详细信息，请参阅相关文章。

尝试使用Roadrunner包装器诱导系统的诱导包装器，它在25个网站的每一个数据集上都可以成功使用但是在变化的五年期中表现很差。
包装器破损是包装诱导技术的一个众所周知的问题。
五年的窗口对于任何包装器来说都太长了，很难继续保持有效。
因此，Roadrunner必须进行有针对性的训练和评估。
在这个案例中，我们手工识别出具有十分相似的HTML结构的网页并且在这些页面中训练包装器。
大多是情况下，同一个域中的90-95%的网页可以被用来生成包装器，但是在两个网站中，只用大约一半的网页是有相似的样式并且是对训练有效的。
我们使用诱导的包装器从其被训练的网页中提取内容。

我们强调，我们的方法遵循大多数内容提取方法。
也就是说，我们下载网页的原始HTMl并且仅在静态HTML中实施内容提取。
我们进一步强调，这忽略了网页整体呈现的很大一部分--网页越来越依靠通过AJAX，样式表，iframe这些外部资源渲染。
这些方法的缺点是很清楚的，但是我们使用它们是因为目前的提取器只需要静态HTML。

1.评估
我们采用标准的内容提取度量来比较不同方法的表现。
通过将每种方法的结果/输出和手工标记的黄金标准进行比较来计算精确度，召回率和F1-scores。
F1-scores按照惯例计算，所有结果都通过对所有样例的每个度量进行平均值计算。

这些指标的主要问题是它们可能会膨胀。
这是因为每个单词在一个文档中是被认为是不同的，即使两个单词在词法上是相同的。
这使得将单词和原始页面联结是不可能的，因此迫使我们将手工标记的内容和自动提取的内容当做是同一包单词，例如，如果两个单词在词法上是相同的，则将它们认为是相同的。
这些单词度量的包更宽松，作为结果，评估分数可能会变得膨胀。

CleanEval竞赛的手工标记的黄金标准也是来自2006年通过"[收集]由四个连续的单独语言进行GOOGLE查询返回的URL"下载的由684个英文页面和653个中文页面组成的共享列表。
CleanEval在计算提取表现时使用一个不同的方法。
他们的评分方法是基于一个一次一词版本的提取算法和黄金标准的编辑距离除以对齐长度。

A.结果
首先，我们对每一个算法在数据集上的结果做一个直接的分析。
图2a-2d展现了根据提取器组织的的每一个五年期中的F1-measure。
例如，BTE提取器在2001年发布，因此它是ca.2000组中的提取器，它的表现在图2a中描述。
eatiht提取器是在2015年发布因此它使ca.2015组中的提取器，在图2d中展示。

图2a-2d中随着时间变化的性能曲线准确的表明这篇论文的主要论点：提取器很快就会过时。
[图2 占位]
图2: 不同提取器类群每五年期的F1-measure

实际上，图3平均了每一个类群的F1-measure并且将他们的总体表现绘制在一起。
我们可以清楚地看到，所有的提取器类群在开始的时候对于2000年的网页数据大概有相同的表现，但是随着网页的形式与功能的变化，性能迅速下降。
作为原始的基准，我们也对如果提取所有非HTML文本并将它们作为内容的情况进行了结果评估，在这种情况下，F1-measure受完美的召回率分数提高，但是精度和准确度和预期的一样差。

2015年的提取器对于Web的变化最具有不变性应为开发者可能会创建了解2015年Web状态和理解Web历史的提取器。
2010年的提取器对2010年以及之前的数据表现的很好，但是不能适应2015年出现的意料之外的变化。
类似地，2005年的提取器对2005年以及之前的数据表现的很好，但是不能预测Web的变化并且很快被淘汰。

F1-measure按理说是分析这类数据的最好的单一性能指标，然而，单独的精度，召回率和准确度的考虑对于某些应用来说可能是重要的。
原始分数在表V中列出。

[图3 占位]
图3:每一个类群每五年期的平均F1值

我们发现2000年和2005年的提取器呈迅速下滑趋势，2010年的提取器也是下滑趋势但曲线并没有那么陡峭。
只有2015年的提取器表现得较为平稳。
这些结果表明，Web设计和实现的变化对内容提取工具产生了不利的影响。

在新的Web标准(如HTML5)中发现的语义标签可能是提取器性能下降的一种解决方案。
表VI表明在仅提取(并且是全部)2015年这一五年期中得数据的article标签内部的文本作为文章内容的情况下，提取器表现出惊人的好的性能。
与表V中所示的复杂算法的结果相比，简单地HTML5提取规则在很小的精力下有更好地结果。

[表V 占位]
表V:每个五年期和提取器类群的精度，召回率和准确度逐渐变差。

[表VI 占位]
表VI:仅提取HTML5的article标签的结果

这进一步表明Web的本质正在改变，因此，我们对内容提取的思考也必须改变。

B.讨论



